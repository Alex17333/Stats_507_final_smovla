{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61faef37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpprint\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdataset\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dataset'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import pprint\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db488013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\19142\\.conda\\envs\\my_robotics\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from lerobot.datasets.lerobot_dataset import LeRobotDataset\n",
    "from lerobot.policies.factory import make_policy\n",
    "from lerobot.policies.smolvla.configuration_smolvla import SmolVLAConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28c8f55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bff48c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'torchcodec' is not available in your platform, falling back to 'pyav' as a default decoder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 19631 frames\n",
      "{'count': array([19631]),\n",
      " 'max': array([ 72.7734375 , 179.47265625, 164.61914062,  96.59179688,\n",
      "       123.57421875,  34.9307785 ]),\n",
      " 'mean': array([ 14.51138199, 146.44867041, 143.31572513,  62.96079529,\n",
      "        85.83100241,   7.78159506]),\n",
      " 'min': array([-37.17773438,  48.8671875 ,  40.95703125,   9.66796875,\n",
      "        56.25      ,   0.        ]),\n",
      " 'std': array([27.98693199, 34.98953716, 21.46425995, 16.91135693, 12.47836367,\n",
      "        9.54603304])}\n"
     ]
    }
   ],
   "source": [
    "repo_id = \"lerobot/svla_so100_pickplace\"\n",
    "\n",
    "fps = 30\n",
    "\n",
    "dataset = LeRobotDataset(\n",
    "    repo_id, \n",
    "    episodes=[0],\n",
    "    delta_timestamps={\"action\": [i / fps for i in range(10)]}\n",
    ")\n",
    "\n",
    "print(f\"Dataset loaded: {len(dataset)} frames\")\n",
    "\n",
    "pprint.pprint(dataset.meta.stats[\"action\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0d9ac58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:lerobot.configs.policies:Device 'None' is not available. Switching to 'cuda'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Policy...\n",
      "Reducing the number of VLM layers to 16 ...\n"
     ]
    }
   ],
   "source": [
    "policy_cfg = SmolVLAConfig(\n",
    "    n_action_steps=10,\n",
    "    chunk_size=10,\n",
    "    pretrained_path=\"lerobot/smolvla_base\",\n",
    "    empty_cameras=0\n",
    ")\n",
    "\n",
    "print(\"Building Policy...\")\n",
    "policy = make_policy(\n",
    "    cfg=policy_cfg,\n",
    "    ds_meta=dataset.meta\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f41e501c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "policy.to(device)\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6757254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer_path = \"HuggingFaceTB/SmolVLM-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90d8fead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\19142\\.conda\\envs\\my_robotics\\lib\\site-packages\\torchvision\\io\\_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pick up the cube and place it in the box.\n",
      "Text tokenized shape: torch.Size([1, 64])\n",
      "Lang Mask Shape:   torch.Size([1, 64])\n",
      "Batch keys: dict_keys(['observation.images.top', 'observation.images.wrist', 'action', 'observation.state', 'timestamp', 'frame_index', 'episode_index', 'index', 'task_index', 'action_is_pad', 'observation.language.tokens', 'observation.language.attention_mask'])\n",
      "Image shape: torch.Size([1, 3, 480, 640])\n",
      "Action shape: torch.Size([1, 10, 6])\n"
     ]
    }
   ],
   "source": [
    "item = dataset[0]\n",
    "print(item[\"task\"])\n",
    "\n",
    "encoded_text = tokenizer( \n",
    "    item[\"task\"],\n",
    "    padding=\"max_length\",\n",
    "    max_length=64,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# print(item.items())\n",
    "batch = {k: v.unsqueeze(0).to(device) for k, v in item.items() if isinstance(v, torch.Tensor)}\n",
    "\n",
    "batch[\"observation.language.tokens\"] = encoded_text[\"input_ids\"].to(device)\n",
    "batch[\"observation.language.attention_mask\"] = encoded_text[\"attention_mask\"].to(device).bool()\n",
    "\n",
    "print(\"Text tokenized shape:\", batch[\"observation.language.tokens\"].shape)\n",
    "print(\"Lang Mask Shape:  \", batch[\"observation.language.attention_mask\"].shape)\n",
    "print(\"Batch keys:\", batch.keys())\n",
    "print(f\"Image shape: {batch['observation.images.top'].shape}\")\n",
    "print(f\"Action shape: {batch['action'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02252435",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobservation.state\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m normalize_data(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobservation.state\u001b[39m\u001b[38;5;124m\"\u001b[39m], state_mean, state_std)\n\u001b[0;32m     16\u001b[0m policy\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 17\u001b[0m loss, output_dict \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNormalized Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\19142\\.conda\\envs\\my_robotics\\lib\\site-packages\\lerobot\\policies\\smolvla\\modeling_smolvla.py:326\u001b[0m, in \u001b[0;36mSmolVLAPolicy.forward\u001b[1;34m(self, batch, noise, time)\u001b[0m\n\u001b[0;32m    324\u001b[0m actions_is_pad \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactions_id_pad\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    325\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 326\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m loss_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses_after_forward\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m losses\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m actions_is_pad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\19142\\.conda\\envs\\my_robotics\\lib\\site-packages\\lerobot\\policies\\smolvla\\modeling_smolvla.py:684\u001b[0m, in \u001b[0;36mVLAFlowMatching.forward\u001b[1;34m(self, images, img_masks, lang_tokens, lang_masks, state, actions, noise, time)\u001b[0m\n\u001b[0;32m    682\u001b[0m x_t \u001b[38;5;241m=\u001b[39m time_expanded \u001b[38;5;241m*\u001b[39m noise \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m time_expanded) \u001b[38;5;241m*\u001b[39m actions\n\u001b[0;32m    683\u001b[0m u_t \u001b[38;5;241m=\u001b[39m noise \u001b[38;5;241m-\u001b[39m actions\n\u001b[1;32m--> 684\u001b[0m prefix_embs, prefix_pad_masks, prefix_att_masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_prefix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    687\u001b[0m suffix_embs, suffix_pad_masks, suffix_att_masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_suffix(x_t, time)\n\u001b[0;32m    689\u001b[0m pad_masks \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([prefix_pad_masks, suffix_pad_masks], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\19142\\.conda\\envs\\my_robotics\\lib\\site-packages\\lerobot\\policies\\smolvla\\modeling_smolvla.py:601\u001b[0m, in \u001b[0;36mVLAFlowMatching.embed_prefix\u001b[1;34m(self, images, img_masks, lang_tokens, lang_masks, state)\u001b[0m\n\u001b[0;32m    598\u001b[0m num_lang_embs \u001b[38;5;241m=\u001b[39m lang_emb\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    599\u001b[0m att_masks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m num_lang_embs\n\u001b[1;32m--> 601\u001b[0m state_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    602\u001b[0m state_emb \u001b[38;5;241m=\u001b[39m state_emb[:, \u001b[38;5;28;01mNone\u001b[39;00m, :] \u001b[38;5;28;01mif\u001b[39;00m state_emb\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m state_emb\n\u001b[0;32m    603\u001b[0m embs\u001b[38;5;241m.\u001b[39mappend(state_emb)\n",
      "File \u001b[1;32mc:\\Users\\19142\\.conda\\envs\\my_robotics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\19142\\.conda\\envs\\my_robotics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\19142\\.conda\\envs\\my_robotics\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
     ]
    }
   ],
   "source": [
    "# data processing\n",
    "\n",
    "def normalize_data(data, mean, std):\n",
    "    return (data - mean) / std\n",
    "\n",
    "action_mean = torch.from_numpy(dataset.meta.stats[\"action\"][\"mean\"]).to(device)\n",
    "action_std = torch.from_numpy(dataset.meta.stats[\"action\"][\"std\"]).to(device)\n",
    "\n",
    "batch[\"action\"] = normalize_data(batch[\"action\"], action_mean, action_std)\n",
    "\n",
    "if \"observation.state\" in batch:\n",
    "    state_mean = torch.from_numpy(dataset.meta.stats[\"observation.state\"][\"mean\"]).float().to(device)\n",
    "    state_std = torch.from_numpy(dataset.meta.stats[\"observation.state\"][\"std\"]).float().to(device)\n",
    "    batch[\"observation.state\"] = normalize_data(batch[\"observation.state\"], state_mean, state_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "857b7e20",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m policy\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m----> 3\u001b[0m loss, output_dict \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput dict keys:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_dict\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32mc:\\Users\\19142\\.conda\\envs\\my_robotics\\lib\\site-packages\\lerobot\\policies\\smolvla\\modeling_smolvla.py:326\u001b[0m, in \u001b[0;36mSmolVLAPolicy.forward\u001b[1;34m(self, batch, noise, time)\u001b[0m\n\u001b[0;32m    324\u001b[0m actions_is_pad \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactions_id_pad\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    325\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 326\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m loss_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses_after_forward\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m losses\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m actions_is_pad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\19142\\.conda\\envs\\my_robotics\\lib\\site-packages\\lerobot\\policies\\smolvla\\modeling_smolvla.py:684\u001b[0m, in \u001b[0;36mVLAFlowMatching.forward\u001b[1;34m(self, images, img_masks, lang_tokens, lang_masks, state, actions, noise, time)\u001b[0m\n\u001b[0;32m    682\u001b[0m x_t \u001b[38;5;241m=\u001b[39m time_expanded \u001b[38;5;241m*\u001b[39m noise \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m time_expanded) \u001b[38;5;241m*\u001b[39m actions\n\u001b[0;32m    683\u001b[0m u_t \u001b[38;5;241m=\u001b[39m noise \u001b[38;5;241m-\u001b[39m actions\n\u001b[1;32m--> 684\u001b[0m prefix_embs, prefix_pad_masks, prefix_att_masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_prefix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    687\u001b[0m suffix_embs, suffix_pad_masks, suffix_att_masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_suffix(x_t, time)\n\u001b[0;32m    689\u001b[0m pad_masks \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([prefix_pad_masks, suffix_pad_masks], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\19142\\.conda\\envs\\my_robotics\\lib\\site-packages\\lerobot\\policies\\smolvla\\modeling_smolvla.py:601\u001b[0m, in \u001b[0;36mVLAFlowMatching.embed_prefix\u001b[1;34m(self, images, img_masks, lang_tokens, lang_masks, state)\u001b[0m\n\u001b[0;32m    598\u001b[0m num_lang_embs \u001b[38;5;241m=\u001b[39m lang_emb\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    599\u001b[0m att_masks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m num_lang_embs\n\u001b[1;32m--> 601\u001b[0m state_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    602\u001b[0m state_emb \u001b[38;5;241m=\u001b[39m state_emb[:, \u001b[38;5;28;01mNone\u001b[39;00m, :] \u001b[38;5;28;01mif\u001b[39;00m state_emb\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m state_emb\n\u001b[0;32m    603\u001b[0m embs\u001b[38;5;241m.\u001b[39mappend(state_emb)\n",
      "File \u001b[1;32mc:\\Users\\19142\\.conda\\envs\\my_robotics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\19142\\.conda\\envs\\my_robotics\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\19142\\.conda\\envs\\my_robotics\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
     ]
    }
   ],
   "source": [
    "policy.train()\n",
    "\n",
    "loss, output_dict = policy.forward(batch)\n",
    "\n",
    "print(f\"Loss: {loss.item()}\")\n",
    "print(\"Output dict keys:\", output_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f999d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.eval() # 切换到评估模式\n",
    "\n",
    "with torch.no_grad():\n",
    "    # select_action 通常只需要 observation，不需要 ground truth action\n",
    "    # 但传入整个 batch 也没问题，它会自动挑它需要的 key\n",
    "    action = policy.select_action(batch)\n",
    "\n",
    "print(f\"Generated Action Shape: {action.shape}\") \n",
    "# 预期输出: [1, 10, 14] 或者 [1, 14] \n",
    "# (取决于 chunk_size 和 n_action_steps 的配置，SmolVLA 通常输出一个 chunk)\n",
    "\n",
    "# 简单检查一下数值是否“疯了”（比如全是 NaN 或者极大值）\n",
    "print(\"Action sample:\", action[0, :2]) # 打印前两步动作\n",
    "if torch.isnan(action).any():\n",
    "    print(\"❌ ALERT: Action contains NaN!\")\n",
    "else:\n",
    "    print(\"✅ Action looks valid (numerical-wise).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_robotics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
