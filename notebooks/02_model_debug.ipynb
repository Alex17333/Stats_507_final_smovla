{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61faef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import pprint\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db488013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\19142\\.conda\\envs\\my_robotics\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from lerobot.datasets.lerobot_dataset import LeRobotDataset\n",
    "from lerobot.policies.factory import make_policy\n",
    "from lerobot.policies.smolvla.configuration_smolvla import SmolVLAConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28c8f55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bff48c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'torchcodec' is not available in your platform, falling back to 'pyav' as a default decoder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 19631 frames\n",
      "{'count': array([19631]),\n",
      " 'max': array([ 72.7734375 , 179.47265625, 164.61914062,  96.59179688,\n",
      "       123.57421875,  34.9307785 ]),\n",
      " 'mean': array([ 14.51138199, 146.44867041, 143.31572513,  62.96079529,\n",
      "        85.83100241,   7.78159506]),\n",
      " 'min': array([-37.17773438,  48.8671875 ,  40.95703125,   9.66796875,\n",
      "        56.25      ,   0.        ]),\n",
      " 'std': array([27.98693199, 34.98953716, 21.46425995, 16.91135693, 12.47836367,\n",
      "        9.54603304])}\n"
     ]
    }
   ],
   "source": [
    "repo_id = \"lerobot/svla_so100_pickplace\"\n",
    "\n",
    "dataset = LeRobotDataset(repo_id, episodes=[0])\n",
    "\n",
    "print(f\"Dataset loaded: {len(dataset)} frames\")\n",
    "\n",
    "pprint.pprint(dataset.meta.stats[\"action\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0d9ac58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:lerobot.configs.policies:Device 'None' is not available. Switching to 'cuda'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Policy...\n",
      "Reducing the number of VLM layers to 16 ...\n"
     ]
    }
   ],
   "source": [
    "policy_cfg = SmolVLAConfig(\n",
    "    n_action_steps=10,\n",
    "    chunk_size=10,\n",
    "    pretrained_path=\"lerobot/smolvla_base\",\n",
    "    empty_cameras=0\n",
    ")\n",
    "\n",
    "print(\"Building Policy...\")\n",
    "policy = make_policy(\n",
    "    cfg=policy_cfg,\n",
    "    ds_meta=dataset.meta\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f41e501c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "policy.to(device)\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6757254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer_path = \"HuggingFaceTB/SmolVLM-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90d8fead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pick up the cube and place it in the box.\n",
      "Text tokenized shape: torch.Size([1, 64])\n",
      "Lang Mask Shape:   torch.Size([1, 64])\n",
      "Batch keys: dict_keys(['observation.images.top', 'observation.images.wrist', 'action', 'observation.state', 'timestamp', 'frame_index', 'episode_index', 'index', 'task_index', 'observation.language.tokens', 'observation.language.attention_mask'])\n",
      "Image shape: torch.Size([1, 3, 480, 640])\n",
      "Action shape: torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "item = dataset[0]\n",
    "print(item[\"task\"])\n",
    "\n",
    "encoded_text = tokenizer( \n",
    "    item[\"task\"],\n",
    "    padding=\"max_length\",\n",
    "    max_length=64,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# print(item.items())\n",
    "batch = {k: v.unsqueeze(0).to(device) for k, v in item.items() if isinstance(v, torch.Tensor)}\n",
    "\n",
    "batch[\"observation.language.tokens\"] = encoded_text[\"input_ids\"].to(device)\n",
    "batch[\"observation.language.attention_mask\"] = encoded_text[\"attention_mask\"].to(device)\n",
    "\n",
    "print(\"Text tokenized shape:\", batch[\"observation.language.tokens\"].shape)\n",
    "print(\"Lang Mask Shape:  \", batch[\"observation.language.attention_mask\"].shape)\n",
    "print(\"Batch keys:\", batch.keys())\n",
    "print(f\"Image shape: {batch['observation.images.top'].shape}\")\n",
    "print(f\"Action shape: {batch['action'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "857b7e20",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (203) must match the size of tensor b (194) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m policy\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m----> 3\u001b[0m loss, output_dict \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput dict keys:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_dict\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32mc:\\Users\\19142\\.conda\\envs\\my_robotics\\lib\\site-packages\\lerobot\\policies\\smolvla\\modeling_smolvla.py:326\u001b[0m, in \u001b[0;36mSmolVLAPolicy.forward\u001b[1;34m(self, batch, noise, time)\u001b[0m\n\u001b[0;32m    324\u001b[0m actions_is_pad \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactions_id_pad\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    325\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 326\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m loss_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses_after_forward\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m losses\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m actions_is_pad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\19142\\.conda\\envs\\my_robotics\\lib\\site-packages\\lerobot\\policies\\smolvla\\modeling_smolvla.py:692\u001b[0m, in \u001b[0;36mVLAFlowMatching.forward\u001b[1;34m(self, images, img_masks, lang_tokens, lang_masks, state, actions, noise, time)\u001b[0m\n\u001b[0;32m    689\u001b[0m pad_masks \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([prefix_pad_masks, suffix_pad_masks], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    690\u001b[0m att_masks \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([prefix_att_masks, suffix_att_masks], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 692\u001b[0m att_2d_masks \u001b[38;5;241m=\u001b[39m \u001b[43mmake_att_2d_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matt_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    693\u001b[0m position_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcumsum(pad_masks, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    694\u001b[0m (_, suffix_out), _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvlm_with_expert\u001b[38;5;241m.\u001b[39mforward(\n\u001b[0;32m    695\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39matt_2d_masks,\n\u001b[0;32m    696\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    700\u001b[0m     fill_kv_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    701\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\19142\\.conda\\envs\\my_robotics\\lib\\site-packages\\lerobot\\policies\\smolvla\\modeling_smolvla.py:122\u001b[0m, in \u001b[0;36mmake_att_2d_masks\u001b[1;34m(pad_masks, att_masks)\u001b[0m\n\u001b[0;32m    120\u001b[0m att_2d_masks \u001b[38;5;241m=\u001b[39m cumsum[:, \u001b[38;5;28;01mNone\u001b[39;00m, :] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m cumsum[:, :, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m    121\u001b[0m pad_2d_masks \u001b[38;5;241m=\u001b[39m pad_masks[:, \u001b[38;5;28;01mNone\u001b[39;00m, :] \u001b[38;5;241m*\u001b[39m pad_masks[:, :, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m--> 122\u001b[0m att_2d_masks \u001b[38;5;241m=\u001b[39m \u001b[43matt_2d_masks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpad_2d_masks\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m att_2d_masks\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (203) must match the size of tensor b (194) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "policy.train()\n",
    "\n",
    "loss, output_dict = policy.forward(batch)\n",
    "\n",
    "print(f\"Loss: {loss.item()}\")\n",
    "print(\"Output dict keys:\", output_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f999d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.eval() # 切换到评估模式\n",
    "\n",
    "with torch.no_grad():\n",
    "    # select_action 通常只需要 observation，不需要 ground truth action\n",
    "    # 但传入整个 batch 也没问题，它会自动挑它需要的 key\n",
    "    action = policy.select_action(batch)\n",
    "\n",
    "print(f\"Generated Action Shape: {action.shape}\") \n",
    "# 预期输出: [1, 10, 14] 或者 [1, 14] \n",
    "# (取决于 chunk_size 和 n_action_steps 的配置，SmolVLA 通常输出一个 chunk)\n",
    "\n",
    "# 简单检查一下数值是否“疯了”（比如全是 NaN 或者极大值）\n",
    "print(\"Action sample:\", action[0, :2]) # 打印前两步动作\n",
    "if torch.isnan(action).any():\n",
    "    print(\"❌ ALERT: Action contains NaN!\")\n",
    "else:\n",
    "    print(\"✅ Action looks valid (numerical-wise).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_robotics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
